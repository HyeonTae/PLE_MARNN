{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameter\n",
    "- Attention = True\n",
    "- Teacher Forcing Ratio = 0.5\n",
    "- Dropout = 0.2\n",
    "- Layer = 4\n",
    "- Batch size = 128\n",
    "- Learning rate = 0.001\n",
    "- Hidden unit = 300\n",
    "- Epochs = 20\n",
    "- Data = ids\n",
    "- Raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "import useful packages for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import sqlite3\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "os.chdir(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))\n",
    "\n",
    "from models.seq2seq import Seq2seq\n",
    "from loss.loss import Perplexity\n",
    "from optim.optim import Optimizer\n",
    "from dataset import fields\n",
    "from evaluator.predictor import Predictor\n",
    "from util.helpers import apply_fix, vstack_with_right_padding, make_dir_if_not_exists\n",
    "from util.helpers import InvalidFixLocationException, SubstitutionFailedException\n",
    "from util.helpers import get_lines, extract_line_number, FailedToGetLineNumberException, _truncate_fix\n",
    "from util.helpers import tokens_to_source, compilation_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, \"info\".upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = \"lstm\"\n",
    "data_name = \"ids\"\n",
    "data_type = \"raw\"\n",
    "pretrained_dir_name = None\n",
    "select = \"1\"\n",
    "batch_size = 128\n",
    "iteration = 5\n",
    "\n",
    "train_path = \"data/network_inputs/iitk-\"+data_name+\"-1189\"+\"/data_train.txt\"\n",
    "test_path = \"data/network_inputs/iitk-\"+data_name+\"-1189\"\n",
    "config_path = \"models/config.json\"\n",
    "inverse_vocab_path = \"data/data_generator/target_vocab_reverse.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 450\n",
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter)\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeontae/hyeontae/venv1/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"max_len\": 450,\n",
      "    \"embedding_size\": 50,\n",
      "    \"hidden_size\": 300,\n",
      "    \"input_dropout_p\": 0,\n",
      "    \"dropout_p\": 0.2,\n",
      "    \"n_layers\": 4,\n",
      "    \"bidirectional\": false,\n",
      "    \"rnn_cell\": \"lstm\",\n",
      "    \"variable_lengths\": true,\n",
      "    \"embedding\": null,\n",
      "    \"update_embedding\": true,\n",
      "    \"get_context_vector\": false,\n",
      "    \"use_attention\": true,\n",
      "    \"attn_layers\": 1,\n",
      "    \"hard_attn\": false,\n",
      "    \"position_embedding\": null,\n",
      "    \"pos_add\": \"add\",\n",
      "    \"use_memory\": null,\n",
      "    \"memory_dim\": 5\n",
      "}\n",
      "Save_path : ids_att_emb50_hidden300\n"
     ]
    }
   ],
   "source": [
    "optimizer = \"Adam\"\n",
    "seq2seq = None\n",
    "config_json = open(config_path).read()\n",
    "config = json.loads(config_json)\n",
    "config[\"max_len\"] = 450\n",
    "config[\"hidden_size\"] = 300\n",
    "config[\"rnn_cell\"] = rnn\n",
    "config[\"n_layers\"] = 4\n",
    "config[\"dropout_p\"] = 0.2\n",
    "config[\"embedding_size\"] = 50\n",
    "config[\"use_attention\"] = True\n",
    "config[\"position_embedding\"] = None\n",
    "config[\"use_memory\"] = None\n",
    "#config[\"seed\"]= 1189\n",
    "#config[\"pos_add\"] = \"cat\"\n",
    "\n",
    "print(json.dumps(config, indent=4))\n",
    "    \n",
    "save_path = (data_name\n",
    "            + (\"_att\" if config[\"use_attention\"] else \"\")\n",
    "            + (\"_with_pos_\" + config[\"position_embedding\"] if config[\"position_embedding\"] is not None else \"\")\n",
    "            + (\"_cat\" if config[\"pos_add\"] == \"cat\" else \"\")\n",
    "            + (\"_use_stack\" if config[\"use_memory\"] == \"stack\" else \"\")\n",
    "            + (\"_use_queue\" if config[\"use_memory\"] == \"queue\" else \"\")\n",
    "            + \"_emb\" + str(config[\"embedding_size\"])\n",
    "            + \"_hidden\" + str(config[\"hidden_size\"])\n",
    "            + (\"_pretrained\" if pretrained_dir_name is not None else \"\"))\n",
    "print(\"Save_path : %s\" % save_path)\n",
    "        \n",
    "if pretrained_dir_name is not None:\n",
    "    pretrained_path = (\"pretrained_weights/\"+ data_name + \"_\" + pretrained_dir_name\n",
    "            + (\"_att\" if config[\"use_attention\"] else \"\")\n",
    "            + (\"_with_pos_\" + config[\"position_embedding\"] if config[\"position_embedding\"] is not None else \"\")\n",
    "            + (\"_cat\" if config[\"pos_add\"] == \"cat\" else \"\")\n",
    "            + (\"_use_stack\" if config[\"use_memory\"] == \"stack\" else \"\")\n",
    "            + (\"_use_queue\" if config[\"use_memory\"] == \"queue\" else \"\")\n",
    "            + \"_emb\" + str(config[\"embedding_size\"])\n",
    "            + \"_hidden\" + str(config[\"hidden_size\"])\n",
    "            + \"_\"+rnn+\"_\"+str(i))\n",
    "    pretrained_pos_weight = np.load(pretrained_path+\"/encoder_pos_weight.npy\")\n",
    "    seq2seq = Seq2seq(config, vocab_size, vocab_size, sos_id, eos_id,\n",
    "                      pretrained_pos_weight)\n",
    "else :\n",
    "    seq2seq = Seq2seq(config, len(src.vocab), len(tgt.vocab), tgt.sos_id, tgt.eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = \"log/test/\" + save_path\n",
    "if not os.path.isdir(fig_path):\n",
    "    os.mkdir(fig_path)\n",
    "fig_path = fig_path + \"/\" + rnn\n",
    "if not os.path.isdir(fig_path):\n",
    "    os.mkdir(fig_path)\n",
    "database_path = fig_path + \"/\" + data_type\n",
    "if not os.path.isdir(database_path):\n",
    "    os.mkdir(database_path)\n",
    "database = database_path + \"/\" + data_name + \"_\" + data_type + \".db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "            \n",
    "log_path = \"log/pth/\"+save_path +\"_\" + rnn + \"_\" + str(select) + \"_model_save.pth\"\n",
    "seq2seq.load_state_dict(torch.load(log_path))\n",
    "seq2seq.eval()\n",
    "\n",
    "predictor = Predictor(seq2seq, input_vocab, output_vocab, output_vocab.stoi[train.fields['tgt'].pad_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fix(program):\n",
    "    tgt_seq = predictor.predict_batch(program)\n",
    "    return tgt_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_raw data length : 6978\n"
     ]
    }
   ],
   "source": [
    "if data_type == 'raw':\n",
    "    test_dataset = np.load(os.path.join(\n",
    "        test_path, 'test_%s.npy' % (data_type))).item()\n",
    "else:\n",
    "    test_dataset = np.load(os.path.join(\n",
    "        test_path, 'test_%s-%s.npy' % (data_type, data_name))).item()\n",
    "    \n",
    "print(\"test_{} data length : {}\".format(data_type, sum([len(test_dataset[pid]) for pid in test_dataset])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f28fb754730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(database)\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS programs (\n",
    "                prog_id text NOT NULL,\n",
    "                user_id text NOT NULL,\n",
    "                prob_id text NOT NULL,\n",
    "                code text NOT NULL,\n",
    "                name_dict text NOT NULL,\n",
    "                name_seq text NOT NULL,\n",
    "                PRIMARY KEY(prog_id)\n",
    "             )''')\n",
    "\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS iterations (\n",
    "                prog_id text NOT NULL,\n",
    "                iteration text NOT NULL,\n",
    "                network text NOT NULL,\n",
    "                fix text NOT NULL,\n",
    "                PRIMARY KEY(prog_id, iteration)\n",
    "             )''')\n",
    "\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS error_messages (\n",
    "                prog_id text NOT NULL,\n",
    "                iteration text NOT NULL,\n",
    "                network text NOT NULL,\n",
    "                error_message text NOT NULL,\n",
    "                FOREIGN KEY(prog_id, iteration, network) REFERENCES iterations(prog_id, iteration, network)\n",
    "             )''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_of_programs = {}\n",
    "fixes_suggested_by_network = {}\n",
    "\n",
    "if data_name == 'typo':\n",
    "    normalize_names = True\n",
    "    fix_kind = 'replace'\n",
    "else:\n",
    "    assert data_name == 'ids'\n",
    "    normalize_names = False\n",
    "    fix_kind = 'insert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove line numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_line_numbers(source):\n",
    "    lines = source.count('~')\n",
    "    for l in range(lines):\n",
    "        if l >= 10:\n",
    "            source = source.replace(list(str(l))[0] + \" \" + list(str(l))[1] + \" ~ \", \"\", 1)\n",
    "        else:\n",
    "            source = source.replace(str(l) + \" ~ \", \"\", 1)\n",
    "    source = source.replace(\"  \", \" \")\n",
    "    return source.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(inverse_vocab_path, \"r\") as json_file:\n",
    "    inverse_vocab = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_edits(source, edits):\n",
    "    fixed = []\n",
    "    inserted = 0\n",
    "    insert_tok = [str(i) for i in range(1,111)]\n",
    "    for i, edit in enumerate(edits):\n",
    "        if i - inserted >= len(source):\n",
    "            break\n",
    "        if edit == '0':\n",
    "            fixed.append(source[i - inserted])\n",
    "        elif edit != '-1':\n",
    "            fixed.append(inverse_vocab[str(int(edit)+1)])\n",
    "            if edits[inserted] not in insert_tok:\n",
    "                inserted += 1\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/93 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<keyword>_static _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<type>_int _<id>_3@ _<keyword>_for _<id>_2@ _<id>_4@ _<op>_( _<type>_int _<id>_5@ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_3@ _<op>_&& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_7@ _<op>_) _<id>_3@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_3@ _<op>_) _<op>_; _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_8@ _<op>_, _<id>_6@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_8@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<id>_4@ _<op>_( _<number>_# _<op>_) _<op>_; _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<keyword>_static _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<type>_int _<id>_3@ _<keyword>_for _<id>_2@ _<id>_4@ _<op>_( _<type>_int _<id>_5@ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_3@ _<op>_&& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_7@ _<op>_) _<id>_3@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_3@ _<op>_) _<op>_; _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_8@ _<op>_, _<id>_6@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_8@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<id>_4@ _<op>_( _<number>_# _<op>_) _<op>_; _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_4@ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_5@ _<op>_) _<id>_5@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<type>_int _<id>_8@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_8@ _<op>_) _<id>_8@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_- _<number>_# _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<keyword>_static _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<type>_int _<id>_3@ _<keyword>_for _<id>_2@ _<id>_4@ _<op>_( _<type>_int _<id>_5@ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_3@ _<op>_&& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_7@ _<op>_) _<id>_3@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_3@ _<op>_) _<op>_; _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_8@ _<op>_, _<id>_6@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_8@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<id>_4@ _<op>_( _<number>_# _<op>_) _<op>_; _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_4@ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_5@ _<op>_) _<id>_5@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<type>_int _<id>_8@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_8@ _<op>_) _<id>_8@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_- _<number>_# _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_> _<id>_6@ _<op>_&& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_< _<id>_4@ _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<keyword>_return _<id>_6@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_7@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_, _<id>_5@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_6@ _<op>_< _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<id>_8@ _<op>_= _<id>_6@ _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<keyword>_static _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<type>_int _<id>_3@ _<keyword>_for _<id>_2@ _<id>_4@ _<op>_( _<type>_int _<id>_5@ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_3@ _<op>_&& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_7@ _<op>_) _<id>_3@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_3@ _<op>_) _<op>_; _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_8@ _<op>_, _<id>_6@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_8@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<id>_4@ _<op>_( _<number>_# _<op>_) _<op>_; _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_4@ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_5@ _<op>_) _<id>_5@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<type>_int _<id>_8@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_8@ _<op>_) _<id>_8@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_- _<number>_# _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_> _<id>_6@ _<op>_&& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_< _<id>_4@ _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<keyword>_return _<id>_6@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_7@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_, _<id>_5@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_6@ _<op>_< _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<id>_8@ _<op>_= _<id>_6@ _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_; _<type>_int _<id>_2@ _<op>_( _<type>_int _<id>_3@ _<op>_) _<op>_{ _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<keyword>_if _<op>_( _<id>_4@ _<op>_> _<id>_3@ _<op>_) _<id>_5@ _<op>_= _<id>_3@ _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_6@ _<op>_, _<id>_7@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_6@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<keyword>_for _<op>_( _<id>_8@ _<op>_= _<number>_# _<op>_; _<id>_8@ _<op>_< _<id>_6@ _<op>_; _<id>_8@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_4@ _<op>_[ _<id>_8@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_9@ _<op>_= _<number>_# _<op>_; _<id>_9@ _<op>_< _<id>_7@ _<op>_; _<id>_9@ _<op>_++ _<op>_) _<op>_{ _<id>_10@ _<op>_( _<op>_) _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<keyword>_static _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<type>_int _<id>_3@ _<keyword>_for _<id>_2@ _<id>_4@ _<op>_( _<type>_int _<id>_5@ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_3@ _<op>_&& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_7@ _<op>_) _<id>_3@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_3@ _<op>_) _<op>_; _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_8@ _<op>_, _<id>_6@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_8@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<id>_4@ _<op>_( _<number>_# _<op>_) _<op>_; _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_< _<op>_= _<id>_4@ _<op>_) _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_5@ _<op>_) _<id>_5@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<type>_int _<id>_8@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<id>_2@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_) _<op>_; _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_> _<id>_8@ _<op>_) _<id>_8@ _<op>_= _<id>_1@ _<op>_[ _<id>_6@ _<op>_] _<op>_; _<op>_} _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<type>_int _<id>_6@ _<op>_= _<number>_# _<op>_; _<id>_6@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_6@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_- _<number>_# _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_; _<type>_int _<id>_3@ _<op>_( _<type>_int _<id>_4@ _<op>_) _<op>_{ _<type>_int _<id>_5@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_> _<id>_6@ _<op>_&& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_< _<id>_4@ _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<keyword>_return _<id>_6@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_7@ _<op>_, _<id>_6@ _<op>_= _<number>_# _<op>_, _<id>_5@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_2@ _<op>_, _<op>_& _<id>_7@ _<op>_) _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<id>_2@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_6@ _<op>_< _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_) _<op>_{ _<id>_6@ _<op>_= _<id>_1@ _<op>_[ _<id>_5@ _<op>_] _<op>_; _<op>_} _<op>_} _<id>_8@ _<op>_= _<id>_6@ _<op>_; _<keyword>_for _<op>_( _<id>_5@ _<op>_= _<number>_# _<op>_; _<id>_5@ _<op>_< _<op>_= _<id>_7@ _<op>_; _<id>_5@ _<op>_++ _<op>_) _<op>_{ _<id>_8@ _<op>_= _<id>_3@ _<op>_( _<id>_8@ _<op>_) _<op>_; _<APIcall>_printf _<op>_( _<string>_ _<op>_, _<id>_8@ _<op>_) _<op>_; _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_; _<type>_int _<id>_2@ _<op>_( _<type>_int _<id>_3@ _<op>_) _<op>_{ _<type>_int _<id>_3@ _<op>_= _<number>_# _<op>_; _<keyword>_if _<op>_( _<id>_4@ _<op>_> _<id>_3@ _<op>_) _<id>_5@ _<op>_= _<id>_3@ _<op>_; _<keyword>_return _<id>_5@ _<op>_; _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<type>_int _<id>_6@ _<op>_, _<id>_7@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_6@ _<op>_) _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_7@ _<op>_) _<keyword>_for _<op>_( _<id>_8@ _<op>_= _<number>_# _<op>_; _<id>_8@ _<op>_< _<id>_6@ _<op>_; _<id>_8@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_4@ _<op>_[ _<id>_8@ _<op>_] _<op>_) _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_9@ _<op>_= _<number>_# _<op>_; _<id>_9@ _<op>_< _<id>_7@ _<op>_; _<id>_9@ _<op>_++ _<op>_) _<op>_{ _<id>_10@ _<op>_( _<op>_) _<op>_} _<keyword>_return _<number>_# _<op>_; _<op>_}\n",
      "_<directive>_#include _<include>_<stdio.h> _<type>_int _<id>_1@ _<op>_[ _<number>_# _<op>_] _<op>_= _<op>_{ _<number>_# _<op>_} _<op>_; _<type>_int _<id>_2@ _<op>_, _<id>_3@ _<op>_, _<id>_4@ _<op>_, _<id>_5@ _<op>_; _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<op>_& _<id>_3@ _<op>_, _<op>_& _<id>_4@ _<op>_) _<op>_; _<type>_int _<id>_6@ _<op>_[ _<id>_3@ _<op>_] _<op>_; _<keyword>_for _<op>_( _<id>_2@ _<op>_= _<number>_# _<op>_; _<id>_2@ _<op>_< _<op>_= _<id>_3@ _<op>_; _<id>_2@ _<op>_++ _<op>_) _<op>_{ _<id>_6@ _<op>_[ _<id>_2@ _<op>_] _<op>_= _<number>_# _<op>_; _<op>_} _<keyword>_for _<op>_( _<id>_2@ _<op>_= _<number>_# _<op>_; _<id>_2@ _<op>_< _<op>_= _<id>_3@ _<op>_; _<id>_2@ _<op>_++ _<op>_) _<op>_{ _<APIcall>_scanf _<op>_( _<string>_ _<op>_, _<id>_1@ _<op>_[ _<id>_2@ _<op>_] _<op>_) _<op>_; _<op>_} _<type>_int _<id>_7@ _<op>_( _<type>_int _<id>_8@ _<op>_) _<op>_{ _<op>_} _<keyword>_for _<op>_( _<id>_2@ _<op>_= _<number>_# _<op>_; _<id>_2@ _<op>_< _<op>_= _<id>_3@ _<op>_; _<id>_2@ _<op>_++ _<op>_) _<op>_{ _<keyword>_for _<op>_( _<id>_9@ _<op>_= _<number>_# _<op>_; _<id>_9@ _<op>_< _<op>_= _<id>_3@ _<op>_; _<id>_9@ _<op>_++ _<op>_) _<op>_{ _<keyword>_if _<op>_( _<id>_10@ _<op>_[ _<id>_2@ _<op>_] _<op>_> _<id>_10@ _<op>_[ _<id>_9@ _<op>_] _<op>_) _<op>_{ _<id>_6@ _<op>_[ _<id>_2@ _<op>_] _<op>_++ _<op>_; _<op>_} _<op>_} _<op>_} _<type>_int _<APIcall>_main _<op>_( _<op>_) _<op>_{ _<keyword>_return _<number>_# _<op>_; _<op>_}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-808231be6411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-758655006739>\u001b[0m in \u001b[0;36mget_fix\u001b[0;34m(program)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtgt_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/program_language_error_correction/2020-06-15/PLE/evaluator/predictor.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(self, src_seq)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtgt_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtgt_id_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyeontae/program_language_error_correction/2020-06-15/PLE/evaluator/predictor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtgt_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtgt_id_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for problem_id, test_programs in tqdm(test_dataset.items()):\n",
    "    sequences_of_programs[problem_id] = {}\n",
    "    fixes_suggested_by_network[problem_id] = {}\n",
    "\n",
    "    entries = []\n",
    "    \n",
    "    for program, name_dict, name_sequence, user_id, program_id in test_programs:\n",
    "        sequences_of_programs[problem_id][program_id] = [program]\n",
    "        fixes_suggested_by_network[problem_id][program_id] = []\n",
    "        entries.append(\n",
    "            (program, name_dict, name_sequence, user_id, program_id,))\n",
    "\n",
    "        c.execute(\"INSERT OR IGNORE INTO programs VALUES (?,?,?,?,?,?)\", (program_id,\n",
    "                  user_id, problem_id, program, json.dumps(name_dict), json.dumps(name_sequence)))\n",
    "            \n",
    "\n",
    "    input_ = []\n",
    "        \n",
    "    for i, entry in enumerate(entries):\n",
    "        _, _, _, _, program_id = entry\n",
    "\n",
    "        tmp = sequences_of_programs[problem_id][program_id][-1]\n",
    "        input_.append(remove_line_numbers(tmp))\n",
    "\n",
    "        cnt = 0\n",
    "        fixes = []\n",
    "        for i in range(math.ceil(len(input_)/batch_size)):\n",
    "            if cnt+batch_size > len(input_):\n",
    "                fix = get_fix(input_[cnt:len(input_)])\n",
    "            else:\n",
    "                fix = get_fix(input_[cnt:cnt+batch_size])\n",
    "            cnt += batch_size\n",
    "            fixes += fix\n",
    "    \n",
    "\n",
    "        for source, fix in zip(input_, fixes):\n",
    "            program = apply_edits(source, fix.split())\n",
    "            c.execute(\"INSERT OR IGNORE INTO iterations VALUES (?,?,?,?)\",\n",
    "                     (program_id, 1, data_name, fix))\n",
    "    conn.commit()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [04:10<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for problem_id, test_programs in tqdm(test_dataset.items()):\n",
    "    sequences_of_programs[problem_id] = {}\n",
    "    fixes_suggested_by_network[problem_id] = {}\n",
    "\n",
    "    entries = []\n",
    "    \n",
    "    for program, name_dict, name_sequence, user_id, program_id in test_programs:\n",
    "        sequences_of_programs[problem_id][program_id] = [program]\n",
    "        fixes_suggested_by_network[problem_id][program_id] = []\n",
    "        entries.append(\n",
    "            (program, name_dict, name_sequence, user_id, program_id,))\n",
    "\n",
    "        c.execute(\"INSERT OR IGNORE INTO programs VALUES (?,?,?,?,?,?)\", (program_id,\n",
    "                  user_id, problem_id, program, json.dumps(name_dict), json.dumps(name_sequence)))\n",
    "            \n",
    "    for round_ in range(iteration):\n",
    "        to_delete = []\n",
    "        input_ = []\n",
    "    \n",
    "        for i, entry in enumerate(entries):\n",
    "            _, _, _, _, program_id = entry\n",
    "\n",
    "            if sequences_of_programs[problem_id][program_id][-1] is not None:\n",
    "                tmp = sequences_of_programs[problem_id][program_id][-1]\n",
    "                input_.append(remove_line_numbers(tmp))\n",
    "            else:\n",
    "                to_delete.append(i)\n",
    "                \n",
    "        to_delete = sorted(to_delete)[::-1]\n",
    "\n",
    "        for i in to_delete:\n",
    "            del entries[i]\n",
    "\n",
    "        assert len(input_) == len(entries)\n",
    "\n",
    "        if len(input_) == 0:\n",
    "            #print('Stopping before iteration %d (no programs remain)' % (round_ + 1))\n",
    "            break\n",
    "            \n",
    "        cnt = 0\n",
    "        fixes = []\n",
    "        for i in range(math.ceil(len(input_)/batch_size)):\n",
    "            if cnt+batch_size > len(input_):\n",
    "                fix = get_fix(input_[cnt:len(input_)])\n",
    "            else:\n",
    "                fix = get_fix(input_[cnt:cnt+batch_size])\n",
    "            cnt += batch_size\n",
    "            fixes += fix\n",
    "            \n",
    "        to_delete = []\n",
    "\n",
    "        for source, fix in zip(input_, fixes):\n",
    "            program = apply_edits(source, fix.split())\n",
    "            sequences_of_programs[problem_id][program_id].append(\" \".join(program))\n",
    "        \n",
    "            c.execute(\"INSERT OR IGNORE INTO iterations VALUES (?,?,?,?)\",\n",
    "                     (program_id, round_, data_name, fix))\n",
    "                  \n",
    "        to_delete = sorted(to_delete)[::-1]\n",
    "        \n",
    "        for i in to_delete:\n",
    "            del entries[i]\n",
    "            \n",
    "    conn.commit()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for problem_id, test_programs in test_dataset.items():\n",
    "    sequences_of_programs[problem_id] = {}\n",
    "    fixes_suggested_by_network[problem_id] = {}\n",
    "\n",
    "    entries = []\n",
    "    \n",
    "    for program, name_dict, name_sequence, user_id, program_id in test_programs:\n",
    "        sequences_of_programs[problem_id][program_id] = [program]\n",
    "        fixes_suggested_by_network[problem_id][program_id] = []\n",
    "        entries.append(\n",
    "            (program, name_dict, name_sequence, user_id, program_id,))\n",
    "\n",
    "        c.execute(\"INSERT OR IGNORE INTO programs VALUES (?,?,?,?,?,?)\", (program_id,\n",
    "                  user_id, problem_id, program, json.dumps(name_dict), json.dumps(name_sequence)))\n",
    "            \n",
    "    for round_ in range(iteration):\n",
    "        print(round_)\n",
    "        to_delete = []\n",
    "        input_ = []\n",
    "        \n",
    "        for i, entry in enumerate(entries):\n",
    "            _, _, _, _, program_id = entry\n",
    "\n",
    "            if sequences_of_programs[problem_id][program_id][-1] is not None:\n",
    "                tmp = sequences_of_programs[problem_id][program_id][-1]\n",
    "                input_.append(remove_line_numbers(tmp))\n",
    "            else:\n",
    "                to_delete.append(i)\n",
    "\n",
    "        to_delete = sorted(to_delete)[::-1]\n",
    "\n",
    "        for i in to_delete:\n",
    "            del entries[i]\n",
    "\n",
    "        assert len(input_) == len(entries)\n",
    "\n",
    "        if len(input_) == 0:\n",
    "            print('Stopping before iteration %d (no programs remain)' % (round_ + 1))\n",
    "            break\n",
    "\n",
    "        cnt = 0\n",
    "        fixes = []\n",
    "        for i in range(math.ceil(len(input_)/batch_size)):\n",
    "            if cnt+batch_size > len(input_):\n",
    "                fix = get_fix(input_[cnt:len(input_)])\n",
    "            else:\n",
    "                fix = get_fix(input_[cnt:cnt+batch_size])\n",
    "            cnt += batch_size\n",
    "            fixes += fix\n",
    "            \n",
    "        to_delete = []\n",
    "\n",
    "        #print(len(fixes))\n",
    "        #print(fixes)\n",
    "    #break\n",
    "\n",
    "        # Apply fixes\n",
    "        for i, entry, fix in zip(range(len(fixes)), entries, fixes):\n",
    "            _, _, _, _, program_id = entry\n",
    "\n",
    "            try:\n",
    "                program = apply_fix(sequences_of_programs[problem_id][program_id][-1], fix, fix_kind,\n",
    "                                    flag_replace_ids=False)\n",
    "                sequences_of_programs[problem_id][program_id].append(program)\n",
    "            except ValueError as e:\n",
    "                to_delete.append(i)\n",
    "                sequences_of_programs[problem_id][program_id].append(\n",
    "                    '{{localization_failed}}')\n",
    "            except InvalidFixLocationException as e:\n",
    "                to_delete.append(i)\n",
    "                sequences_of_programs[problem_id][program_id].append(\n",
    "                    '{{localization_failed}}')\n",
    "            except SubstitutionFailedException as e:\n",
    "                to_delete.append(i)\n",
    "                sequences_of_programs[problem_id][program_id].append(\n",
    "                    '{{back_substitution_failed}}')\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "            else:\n",
    "                c.execute(\"INSERT OR IGNORE INTO iterations VALUES (?,?,?,?)\",\n",
    "                      (program_id, round_ + 1, data_name, fix))\n",
    "                \n",
    "        to_delete = sorted(to_delete)[::-1]\n",
    "        \n",
    "        for i in to_delete:\n",
    "            del entries[i]\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_stop_signal(fix):\n",
    "    if _truncate_fix(fix) == '':\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meets criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meets_criterion(incorrect_program_tokens, fix, type_, silent=True):\n",
    "    lines = get_lines(incorrect_program_tokens)\n",
    "    fix = _truncate_fix(fix)\n",
    "\n",
    "    if _is_stop_signal(fix):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        fix_line_number = extract_line_number(fix)\n",
    "    except FailedToGetLineNumberException:\n",
    "        return False\n",
    "\n",
    "    if fix_line_number >= len(lines):\n",
    "        return False\n",
    "\n",
    "    fix_line = lines[fix_line_number]\n",
    "\n",
    "    # Make sure number of IDs is the same\n",
    "    if len(re.findall('_<id>_\\w*', fix_line)) != len(re.findall('_<id>_\\w*', fix)):\n",
    "        if not silent:\n",
    "            print('number of ids is not the same')\n",
    "        return False\n",
    "\n",
    "    keywords_regex = '_<keyword>_\\w+|_<type>_\\w+|_<APIcall>_\\w+|_<include>_\\w+'\n",
    "\n",
    "    if type_ == 'replace' and re.findall(keywords_regex, fix_line) != re.findall(keywords_regex, fix):\n",
    "        if not silent:\n",
    "            print('important words (keywords, etc.) change drastically')\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_results(database):\n",
    "    with sqlite3.connect(database) as conn:\n",
    "        c = conn.cursor()\n",
    "\n",
    "        error_counts = []\n",
    "\n",
    "        for row in c.execute(\"SELECT iteration, COUNT(*) FROM error_messages GROUP BY iteration ORDER BY iteration;\"):\n",
    "            error_counts.append(row[1])\n",
    "\n",
    "        query1 = \"\"\"SELECT COUNT(*)\n",
    "        FROM error_messages\n",
    "        WHERE iteration = 0 AND prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"\"\"\n",
    "\n",
    "        for row in c.execute(query1):\n",
    "            initial_errors = row[0]\n",
    "\n",
    "        query2 = \"\"\"SELECT COUNT(*)\n",
    "        FROM error_messages\n",
    "        WHERE iteration = 10 AND prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"\"\"\n",
    "\n",
    "        for row in c.execute(query2):\n",
    "            final_errors = row[0]\n",
    "\n",
    "        query3 = \"\"\"SELECT COUNT(DISTINCT prog_id)\n",
    "        FROM error_message_strings\n",
    "        WHERE iteration = 10 AND error_message_count = 0 and prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"\"\"\n",
    "\n",
    "        for row in c.execute(query3):\n",
    "            fully_fixed = row[0]\n",
    "\n",
    "        query4 = \"\"\"SELECT DISTINCT prog_id, error_message_count FROM error_message_strings\n",
    "        WHERE iteration = 0 AND error_message_count > 0 and prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"\"\"\n",
    "\n",
    "        query5 = \"\"\"SELECT DISTINCT prog_id, error_message_count FROM error_message_strings\n",
    "        WHERE iteration = 10 AND error_message_count > 0 and prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"\"\"\n",
    "\n",
    "        original_errors = {}\n",
    "        for row in c.execute(query4):\n",
    "            original_errors[row[0]] = int(row[1])\n",
    "\n",
    "        partially_fixed = {}\n",
    "        unfixed = {}\n",
    "        for row in c.execute(query5):\n",
    "            if int(row[1]) < original_errors[row[0]]:\n",
    "                partially_fixed[row[0]] = int(row[1])\n",
    "            elif int(row[1]) == original_errors[row[0]]:\n",
    "                unfixed[row[0]] = int(row[1])\n",
    "            else:\n",
    "                print(row[0], row[1], original_errors[row[0]])\n",
    "\n",
    "        token_counts = []\n",
    "        assignments = None\n",
    "\n",
    "        for row in c.execute(\"SELECT COUNT(DISTINCT prob_id) FROM programs p WHERE prog_id NOT IN (SELECT p.prog_id FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count = 0);\"):\n",
    "            assignments = int(row[0])\n",
    "\n",
    "        for row in c.execute(\"SELECT code FROM programs p INNER JOIN error_message_strings e ON p.prog_id = e.prog_id WHERE e.iteration = 0 AND e.error_message_count <> 0;\"):\n",
    "            token_counts += [len(row[0].split())]\n",
    "\n",
    "        avg_token_count = np.mean(token_counts)\n",
    "\n",
    "        print(\"-------\")\n",
    "        print(\"Assignments:\", assignments)\n",
    "        print(\"Program count:\", len(token_counts))\n",
    "        print(\"Average token count:\", avg_token_count)\n",
    "        print(\"Error messages:\", initial_errors)\n",
    "        print(\"-------\")\n",
    "\n",
    "        print(\"Errors remaining:\", final_errors)\n",
    "        print(\"Reduction in errors:\", (initial_errors - final_errors))\n",
    "        print(\"Completely fixed programs:\", fully_fixed)\n",
    "        print(\"partially fixed programs:\", len(partially_fixed))\n",
    "        print(\"unfixed programs:\", len(unfixed))\n",
    "        print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_problem(problem_id):\n",
    "    global reconstruction, errors, errors_full, total_count, errors_test\n",
    "\n",
    "    c = conn.cursor()\n",
    "\n",
    "    reconstruction[problem_id] = {}\n",
    "    errors[problem_id] = {}\n",
    "    errors_full[problem_id] = {}\n",
    "    errors_test[problem_id] = []\n",
    "    candidate_programs = []\n",
    "\n",
    "    for row in c.execute('SELECT user_id, prog_id, code, name_dict, name_seq FROM programs WHERE prob_id = ?', (problem_id,)):\n",
    "        user_id, prog_id, initial = row[0], row[1], row[2]\n",
    "        name_dict = json.loads(row[3])\n",
    "        name_seq = json.loads(row[4])\n",
    "\n",
    "        candidate_programs.append(\n",
    "            (user_id, prog_id, initial, name_dict, name_seq,))\n",
    "\n",
    "    for _, prog_id, initial, name_dict, name_seq in candidate_programs:\n",
    "        fixes_suggested_by_typo_network = []\n",
    "        fixes_suggested_by_undeclared_network = []\n",
    "\n",
    "        for row in c.execute('SELECT fix FROM iterations WHERE prog_id=? AND network = \\'typo\\' ORDER BY iteration', (prog_id,)):\n",
    "            fixes_suggested_by_typo_network.append(row[0])\n",
    "\n",
    "        for row in c.execute('SELECT fix FROM iterations WHERE prog_id=? AND network = \\'ids\\' ORDER BY iteration', (prog_id,)):\n",
    "            fixes_suggested_by_undeclared_network.append(row[0])\n",
    "\n",
    "        reconstruction[problem_id][prog_id] = [initial]\n",
    "        temp_errors, temp_errors_full = compilation_errors(\n",
    "            tokens_to_source(initial, name_dict, False), database_path)\n",
    "        errors[problem_id][prog_id] = [temp_errors]\n",
    "        errors_full[problem_id][prog_id] = [temp_errors_full]\n",
    "\n",
    "        try:\n",
    "            for fix in fixes_suggested_by_typo_network:\n",
    "                if meets_criterion(reconstruction[problem_id][prog_id][-1], fix, 'replace'):\n",
    "                    temp_prog = apply_fix(\n",
    "                        reconstruction[problem_id][prog_id][-1], fix, 'replace')\n",
    "                    temp_errors, temp_errors_full = compilation_errors(\n",
    "                        tokens_to_source(temp_prog, name_dict, False), database_path)\n",
    "\n",
    "                    if len(temp_errors) > len(errors[problem_id][prog_id][-1]):\n",
    "                        break\n",
    "                    else:\n",
    "                        reconstruction[problem_id][prog_id].append(temp_prog)\n",
    "                        errors[problem_id][prog_id].append(temp_errors)\n",
    "                        errors_full[problem_id][prog_id].append(\n",
    "                            temp_errors_full)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        except InvalidFixLocationException:\n",
    "            print('Localization failed')\n",
    "\n",
    "        while len(reconstruction[problem_id][prog_id]) <= 5:\n",
    "            reconstruction[problem_id][prog_id].append(\n",
    "                reconstruction[problem_id][prog_id][-1])\n",
    "            errors[problem_id][prog_id].append(errors[problem_id][prog_id][-1])\n",
    "            errors_full[problem_id][prog_id].append(\n",
    "                errors_full[problem_id][prog_id][-1])\n",
    "\n",
    "        already_fixed = []\n",
    "\n",
    "        try:\n",
    "            for fix in fixes_suggested_by_undeclared_network:\n",
    "                if fix not in already_fixed:\n",
    "                    temp_prog = apply_fix(\n",
    "                        reconstruction[problem_id][prog_id][-1], fix, 'insert')\n",
    "                    already_fixed.append(fix)\n",
    "                    temp_errors, temp_errors_full = compilation_errors(\n",
    "                        tokens_to_source(temp_prog, name_dict, False), database_path)\n",
    "\n",
    "                    if len(temp_errors) > len(errors[problem_id][prog_id][-1]):\n",
    "                        break\n",
    "                    else:\n",
    "                        reconstruction[problem_id][prog_id].append(temp_prog)\n",
    "                        errors[problem_id][prog_id].append(temp_errors)\n",
    "                        errors_full[problem_id][prog_id].append(\n",
    "                            temp_errors_full)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        except InvalidFixLocationException:\n",
    "            print('Localization failed')\n",
    "\n",
    "        while len(reconstruction[problem_id][prog_id]) <= 10:\n",
    "            reconstruction[problem_id][prog_id].append(\n",
    "                reconstruction[problem_id][prog_id][-1])\n",
    "            errors[problem_id][prog_id].append(errors[problem_id][prog_id][-1])\n",
    "            errors_full[problem_id][prog_id].append(\n",
    "                errors_full[problem_id][prog_id][-1])\n",
    "\n",
    "        errors_test[problem_id].append(errors[problem_id][prog_id])\n",
    "\n",
    "        for k, errors_t, errors_full_t in zip(range(len(errors[problem_id][prog_id])), errors[problem_id][prog_id], errors_full[problem_id][prog_id]):\n",
    "            c.execute(\"INSERT INTO error_message_strings VALUES(?, ?, ?, ?, ?)\", (\n",
    "                prog_id, k, 'typo', errors_full_t.decode('utf-8', 'ignore'), len(errors_t)))\n",
    "\n",
    "            for error_ in errors_t:\n",
    "                c.execute(\"INSERT INTO error_messages VALUES(?, ?, ?, ?)\",\n",
    "                            (prog_id, k, 'typo', error_.decode('utf-8', 'ignore'),))\n",
    "\n",
    "    count_t = len(candidate_programs)\n",
    "    total_count += count_t\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(arr1, arr2):\n",
    "    for x in arr1:\n",
    "        if x not in arr2:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(database)\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS error_message_strings (\n",
    "                prog_id text NOT NULL,\n",
    "                iteration text NOT NULL,\n",
    "                network text NOT NULL,\n",
    "                error_message_string text NOT NULL,\n",
    "                error_message_count integer NOT NULL,\n",
    "                FOREIGN KEY(prog_id, iteration, network) REFERENCES iterations(prog_id, iteration, network)\n",
    "             )''')\n",
    "\n",
    "problem_ids = []\n",
    "\n",
    "for row in c.execute('SELECT DISTINCT prob_id FROM programs'):\n",
    "    problem_ids.append(row[0])\n",
    "\n",
    "c.close()\n",
    "\n",
    "reconstruction = {}\n",
    "errors = {}\n",
    "errors_full = {}\n",
    "errors_test = {}\n",
    "\n",
    "fixes_per_stage = [0] * 10\n",
    "\n",
    "total_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for problem_id in tqdm(problem_ids):\n",
    "    do_problem(problem_id)\n",
    "\n",
    "time_t = time.time() - start\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print('Total time:', time_t, 'seconds')\n",
    "print('Total programs processed:', total_count)\n",
    "print('Average time per program:', int(float(time_t) / float(total_count) * 1000), 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fixes_num = {}\n",
    "errors_before = {}\n",
    "\n",
    "for problem_id in errors_test:\n",
    "    total_fixes_num[problem_id] = 0\n",
    "\n",
    "    for j, seq in enumerate(errors_test[problem_id]):\n",
    "        error_numbers = [len(x) for x in seq]\n",
    "        skip = False\n",
    "\n",
    "        for i in range(len(error_numbers) - 1):\n",
    "            assert (not error_numbers[i + 1] > error_numbers[i])\n",
    "            total_fixes_num[problem_id] += error_numbers[i] - \\\n",
    "                error_numbers[i + 1]\n",
    "\n",
    "            if error_numbers[i] != error_numbers[i + 1]:\n",
    "                fixes_per_stage[i] += error_numbers[i] - error_numbers[i + 1]\n",
    "\n",
    "total_numerator = 0\n",
    "total_denominator = 0\n",
    "\n",
    "for problem_id in errors_test:\n",
    "    total_numerator += total_fixes_num[problem_id]\n",
    "    total_denominator += sum([len(x[0]) for x in errors_test[problem_id]])\n",
    "\n",
    "\n",
    "print(int(float(total_numerator) * 100.0 / float(total_denominator)), '%')\n",
    "\n",
    "\n",
    "for stage in range(len(fixes_per_stage)):\n",
    "    print('Stage', stage, ':', fixes_per_stage[stage])\n",
    "\n",
    "get_final_results(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
